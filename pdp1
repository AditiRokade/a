Below is a **full AWS Glue notebook-compatible PySpark script** that:

- Fetches **partition columns and partition values dynamically** from the **Glue Catalog for an Athena table**
- Builds **push down predicates dynamically** selecting any subset of partition columns by index
- Uses the predicates to read data from the Glue Catalog table with **push_down_predicate**

***

```python
import boto3
from awsglue.context import GlueContext
from pyspark.context import SparkContext

# Initialize Spark and Glue contexts
sc = SparkContext.getOrCreate()
glueContext = GlueContext(sc)
spark = glueContext.spark_session

def get_partition_columns_from_glue(database, table):
    glue = boto3.client('glue')
    response = glue.get_table(DatabaseName=database, Name=table)
    return [col['Name'] for col in response['Table']['PartitionKeys']]

def get_partition_values_from_glue(database, table):
    glue = boto3.client('glue')
    paginator = glue.get_paginator('get_partitions')
    partitions = []
    for page in paginator.paginate(DatabaseName=database, TableName=table):
        for partition in page['Partitions']:
            partitions.append(partition['Values'])
    return partitions

def build_dynamic_pushdown_predicates(all_part_cols, partition_values_groups, selected_indexes=None):
    if selected_indexes is None:
        selected_indexes = list(range(len(all_part_cols)))
    selected_columns = [all_part_cols[i] for i in selected_indexes]
    predicates = []
    for values in partition_values_groups:
        selected_values = [values[i] for i in selected_indexes]
        pairs = [f"{col}='{val}'" for col, val in zip(selected_columns, selected_values)]
        predicates.append(' and '.join(pairs))
    return predicates

# User inputs
database = 'my_athena_database'
table = 'my_partitioned_table'

# Step 1: Fetch partition metadata dynamically
partition_columns = get_partition_columns_from_glue(database, table)
partition_values = get_partition_values_from_glue(database, table)

# Step 2: Optionally choose subset of partition columns to push down (e.g. 2nd, 3rd, 4th partitions)
selected_partition_indexes = [1, 2, 3]  # change as needed

# Step 3: Build pushdown predicates dynamically
predicates = build_dynamic_pushdown_predicates(partition_columns, partition_values, selected_partition_indexes)

# Optional: Print predicates or limit them for debugging
print(f"Using {len(predicates)} push down predicates:")
for pred in predicates[:5]:  # print only first 5 for brevity
    print(pred)

# Step 4: Use push_down_predicate in Glue DynamicFrame read call â€“ only one predicate can be used per call
# (You normally loop over predicates to read partitions batch-wise if many)

# Example: reading data for first predicate only
push_down_predicate_to_use = predicates[0] if predicates else None

dynamic_frame = glueContext.create_dynamic_frame.from_catalog(
    database=database,
    table_name=table,
    push_down_predicate=push_down_predicate_to_use
)

# Show some records for verification
dynamic_frame.show(10)
```

***

### Notes
- This script dynamically gets partition keys and all partition values from Glue Catalog metadata backing Athena.
- It builds the push_down_predicate string(s) dynamically by selecting any subset of partition columns.
- AWS Glue's `create_dynamic_frame.from_catalog` accepts one `push_down_predicate` string per read call; to read multiple partitions in parallel or batch, iterate over predicates.
- This approach keeps your workload dynamic and adaptive based on the actual Athena table partitions.
- Remember to replace `database` and `table` with your Athena database and table names.

